# voice/ingest_voice_chroma.py
from pathlib import Path
import json
from typing import List
from langchain_community.embeddings import OllamaEmbeddings
# â¬‡ï¸ ê¶Œê³ ëŒ€ë¡œ ìµœì‹  íŒ¨í‚¤ì§€ ì‚¬ìš©
from langchain_chroma import Chroma
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

BASE_URL   = "http://127.0.0.1:11434"
EMBED_MODEL = "bge-m3"
DATA_FILE   = Path("data/voice_transcripts/transcripts.jsonl")
PERSIST_DIR = "vectorstores/voices_bge_m3"
COLLECTION  = "voices_bge_m3"

def load_docs() -> List[Document]:
    docs: List[Document] = []
    if not DATA_FILE.exists():
        print(f"â— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {DATA_FILE}")
        return docs
    with DATA_FILE.open("r", encoding="utf-8") as f:
        for line in f:
            r = json.loads(line)
            text = (r.get("text") or "").strip()
            if not text:
                continue  # â¬…ï¸ ë¹ˆ í…ìŠ¤íŠ¸ ìŠ¤í‚µ
            meta = {
                "doc_id": r.get("doc_id"),
                "source": r.get("source", "voice"),
                "title": r.get("title"),
                "created_at": r.get("created_at"),
            }
            docs.append(Document(page_content=text, metadata=meta))
    return docs

def main():
    print("ğŸ”§ load voice docs...")
    raw_docs = load_docs()
    # ë¹ˆ ê²½ìš° ì•ˆì „ ì¢…ë£Œ
    if not raw_docs:
        print("â— ìœ íš¨í•œ ë³´ì´ìŠ¤ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. STT ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1024, chunk_overlap=128, separators=["\n\n", "\n", " ", ""]
    )
    chunks = [d for d in splitter.split_documents(raw_docs) if d.page_content.strip()]
    if not chunks:
        print("â— ë³´ì´ìŠ¤ ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ ìˆì„ ìˆ˜ ìˆì–´ìš”.")
        return

    embeddings = OllamaEmbeddings(base_url=BASE_URL, model=EMBED_MODEL)
    vs = Chroma(collection_name=COLLECTION, embedding_function=embeddings, persist_directory=PERSIST_DIR)
    vs.add_documents(chunks)
    print(f"âœ… indexed {len(chunks)} chunks â†’ {PERSIST_DIR} ({COLLECTION})")

if __name__ == "__main__":
    main()
